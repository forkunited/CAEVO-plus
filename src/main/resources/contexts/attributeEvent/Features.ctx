context util = EventMentionString(initScript="/util/Util.ctx", initOnce="true");

ts_str_fn str=String();
str_fn trim = Trim();
str_fn lwr = StringCase(type="LOWER");
str_fn rmvSym = StringReplace(mode="REGEX", target="[\\W&&[^\\s]]+", replace=" ");
str_fn rplNum = StringReplace(mode="REGEX", target="\\d+", replace="[D]");
str_fn usToSpc = StringReplace(mode="LITERAL", target="_", replace=" ");
str_fn rmvLong = RemoveLongStringParts(maxLength="30", partSplit="\\s+", partGlue=" "); 
str_fn stem = StemStringParts(partSplit="\\s+", partGlue=" ");
str_fn spcToUs = StringReplace(mode="LITERAL", target=" ", replace="_");

ts_str_fn strClean = Composite(f=(${spcToUs} o ${stem} o ${rmvLong} o ${trim} o ${usToSpc} o ${rplNum} o ${rmvSym} o ${lwr} o ${trim}), 
                               g=${str});
ts_str_fn strDef = Composite(f=(${trim} o ${lwr}), g=${str});
ts_str_fn strTrim = Composite(f=${trim}, g=${str});

ts_fn head = Head();
ts_fn after2 = NGramContext(type="AFTER", n="2");
ts_fn before2 = NGramContext(type="BEFORE", n="2");
ts_fn afterS2 = NGramContext(type="AFTER", n="2", sentenceBoundaryMode="SQUEEZE");
ts_fn beforeS2 = NGramContext(type="BEFORE", n="2", sentenceBoundaryMode="SQUEEZE");
ts_fn beforeI1 = NGramContext(type="BEFORE_INCLUDING", n="1");
ts_fn afterI1 = NGramContext(type="AFTER_INCLUDING", n="1");
ts_fn beforeAfterS2 = NGramContext(type="BEFORE_AND_AFTER", n="2", sentenceBoundaryMode="SQUEEZE");
ts_fn inside1 = NGramInside(n="1");
ts_fn dep = DependencyRelation(mode="PARENTS_AND_CHILDREN");
ts_fn prep = PrepositionOfClause();

ts_str_fn pos = PoS();
ts_str_fn nlpLemma = TokenAnnotation(annotationType="lemma");
ts_str_fn lemma = WordNetLemma();
ts_str_fn synset = WordNetSynset();
ts_str_fn sentPos = SentencePosition();
ts_str_fn depStr = TokenSpanPathStr(mode="ALL", pathLength="1", spanFn1=${dep}, strFn=${strDef});
ts_str_fn pred = PredicateSense();
ts_str_fn depLemma = TokenSpanPathStr(mode="ALL", pathLength="1", spanFn1=${dep}, strFn=${nlpLemma}, multiRelation="true"); 
ts_str_fn depRel = TokenSpanPathStr(mode="ONLY_RELATIONS", pathLength="1", spanFn1=${dep}, strFn=${nlpLemma}, multiRelation="true"); 

feature fTokenB = TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=(${strDef} o ${inside1} o ${beforeS2}));
feature fTokenA = TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=(${strDef} o ${inside1} o ${afterS2}));
feature fPos = TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=${pos});
feature fPosB = TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=(${pos} o ${inside1} o ${beforeS2}));
feature fPosBI = TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=(${pos} o ${beforeI1}));
feature fPosB2 = TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=(${pos} o ${before2}));
feature fPosA = TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=(${pos} o ${inside1} o ${afterS2}));
feature fPosAI = TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=(${pos} o ${afterI1}));
feature fPosA2 = TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=(${pos} o ${after2}));
feature fPrep = TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=(${strDef} o ${prep}));
feature fLemma = TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=${nlpLemma});
feature fSynset = TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=${synset});
feature fSentPos = TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=${sentPos});
feature fSentPosPos = Conjunction(minFeatureOccurrence="2", features=(${fSentPos}, ${fPos}));
feature fW2v = Word2Vec(tokenExtractor="Mention", mode="VECTOR", fn=(${strTrim} o ${head}));
feature fPred= TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=(${pred} o ${head}));
feature fDep=TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=${depLemma});
feature fDepRel=TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="Mention", fn=${depRel});

